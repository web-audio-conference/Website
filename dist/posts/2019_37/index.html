<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport" />
  <meta content="ie=edge" http-equiv="X-UA-Compatible" />
  <link crossorigin="anonymous" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" rel="stylesheet">
  <script src="https://kit.fontawesome.com/0cb65f14a9.js"></script>
  <link href="/assets/css/style.css" rel="stylesheet" type="text/css" />
  <title>
    WAC
    |
    Neural Audio Synthesis on the Web
  </title>

</head>

<body>

  <a href="/"><img alt="Responsive image" class="img-fluid" src="/assets/images/wac-header.png"></a>
  <nav class="navbar sticky-top navbar-expand-lg navbar-dark bg-dark">
    <!--a class="navbar-brand" href="/">WAC</a-->
    <button aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"
      class="navbar-toggler" data-target="#navbarSupportedContent" data-toggle="collapse" type="button">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <div class="mx-auto">
        <ul class="navbar-nav">
          <li  class="nav-item" >
            <a class="nav-link" href="/">Home<span class="sr-only">(current)</span>
            </a>
          </li>
          <li  class="nav-item" >
            <a class="nav-link" href="/past">Past WACs</a>
          </li>
          <li  class="nav-item" >
            <a class="nav-link" href="/proceedings">Proceedings</a>
          </li>
          <li  class="nav-item" >
            <a class="nav-link" href="/code-of-conduct">Code of Conduct</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <main class="container">
    
<div class=" mb-5 mx-auto">
  <div class="row justify-content-md-center">
    <div class="col-sm">
      <h1 class="title text-center" id="title">Neural Audio Synthesis on the Web</h1>
      <div>
        <div class="author">Tero Parviainen</div>

        <div class="row">
          <div class="col-xl-6">
            <div class="abstract">In this talk, I will survey the state of the art in the use of deep neural networks for audio synthesis, with a particular emphasis in using these approaches in web-based applications. I will demonstrate a concrete example of a musical instrument called GANHarp, which produces sounds fully synthesized inside the web browser using Generative Adversarial Networks. Generative uses of deep neural networks are currently getting a lot of attention particularly in the domain of image and text generation. But large advances are also being made in the domain of music. Research groups such as Google Magenta are producing a steady stream of models, datasets, and techniques that advance the use of AI in creative musical expression.While much of this research has been in the symbolic domain (i.e. MIDI, not audio), progress is also being made in the audio domain. This progress is often driven by the needs of speech generation applications, but the same research usually also applies to music, as is often explicitly stated in the research papers.Along with this ongoing research, the technology for applying neural audio models in JavaScript environments – most importantly the web browser – is also becoming increasingly mature. Google’s TensorFlow.js is the leading contender in this space.GANHarp is an experimental musical instrument that explores some of these new advances in neural audio generation, and does all of this within the web browser environment. GANHarp’s timbres are entirely generated by Magenta’s GANSynth model. It allows the player to interpolate between these timbres in real time – think of morphing between the sound of a violin and the sound of a marimba while you are playing. It additionally uses AudioWorklets for real time sample accurate wavetable lookup, and WebGL for 3D visualization. I hope it will act as an early example of a fruitful new approach to designing and delivering tools for musical expression on the web.</div>
          </div>
          <div class="col-xl-6">
            <pre class="bibtex">
            <code>
@inproceedings&#123;,
  abstract = &#123;In this talk, I will survey the state of the art in the use of deep neural networks for audio synthesis, with a particular emphasis in using these approaches in web-based applications. I will demonstrate a concrete example of a musical instrument called GANHarp, which produces sounds fully synthesized inside the web browser using Generative Adversarial Networks. Generative uses of deep neural networks are currently getting a lot of attention particularly in the domain of image and text generation. But large advances are also being made in the domain of music. Research groups such as Google Magenta are producing a steady stream of models, datasets, and techniques that advance the use of AI in creative musical expression.While much of this research has been in the symbolic domain (i.e. MIDI, not audio), progress is also being made in the audio domain. This progress is often driven by the needs of speech generation applications, but the same research usually also applies to music, as is often explicitly stated in the research papers.Along with this ongoing research, the technology for applying neural audio models in JavaScript environments – most importantly the web browser – is also becoming increasingly mature. Google’s TensorFlow.js is the leading contender in this space.GANHarp is an experimental musical instrument that explores some of these new advances in neural audio generation, and does all of this within the web browser environment. GANHarp’s timbres are entirely generated by Magenta’s GANSynth model. It allows the player to interpolate between these timbres in real time – think of morphing between the sound of a violin and the sound of a marimba while you are playing. It additionally uses AudioWorklets for real time sample accurate wavetable lookup, and WebGL for 3D visualization. I hope it will act as an early example of a fruitful new approach to designing and delivering tools for musical expression on the web.&#125;,
  address = &#123;Trondheim&#125;,
  author = &#123;Parviainen, Tero&#125;,
  booktitle = &#123;Proceedings of the International Web Audio Conference 2019&#125;,
  editor = &#123;&#125;,
  month = &#123;December&#125;,
  pages = &#123;&#125;,
  publisher = &#123;NTNU&#125;,
  series = &#123;WAC'19&#125;,
  title = &#123;Neural Audio Synthesis on the Web&#125;,
  year = &#123;2019&#125;,
  ISSN = &#123;&#125;
}
              </code>
            </pre>
          </div>
        </div>
        <div class="row mb-5">
          <div class="col-xl-6">
            <div>
              
              <a href="/_data/papers/pdf/2019/2019_37.pdf" target="blank" class="PDF">Download PDF</a>
               
              <a href="" target="blank" class="media">Watch video</a>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
  </main>

  <footer class="fixed-bottom py-2 bg-dark text-light">
    <div class="container-fluid">
      <div class="row" style="color:gray;">
        <div class="col-md-6 text-md-left text-center align-self-center" id="developers">
          Developed by: <a href="https://github.com/MeltingPlanet" target="_blank" class="devLink" rel="noopener">Jørgen Varpe</a> and
          <a href="https://github.com/MeltingPlanet" target="_blank" class="devLink" rel="noopener">Eigil Aandahl</a>
        </div>
        <div class="col-md-6 text-md-right text-center align-self-center">
          <a href="https://twitter.com/webaudioconf" target="_blank" rel="noopener">
            <img src="/assets/images/twitter.svg" width="40px" height="40px" id="bird" />
          </a>
        </div>
      </div>
    </div>
  </footer>

  <script crossorigin="anonymous" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script crossorigin="anonymous" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
    src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script crossorigin="anonymous" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
    src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</body>

</html>
