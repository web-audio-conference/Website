<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8" />
  <meta content="width=device-width, initial-scale=1.0, shrink-to-fit=no" name="viewport" />
  <meta content="ie=edge" http-equiv="X-UA-Compatible" />
  <link crossorigin="anonymous" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css"
    integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" rel="stylesheet">
  <script src="https://kit.fontawesome.com/0cb65f14a9.js"></script>
  <link href="/assets/css/style.css" rel="stylesheet" type="text/css" />
  <title>
    WAC
    |
    reNotate: The Crowdsourcing and Gamification of Symbolic Music Encoding
  </title>

</head>

<body>

  <a href="/"><img alt="Responsive image" class="img-fluid" src="/assets/images/wac-header.png"></a>
  <nav class="navbar sticky-top navbar-expand-lg navbar-dark bg-dark">
    <!--a class="navbar-brand" href="/">WAC</a-->
    <button aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation"
      class="navbar-toggler" data-target="#navbarSupportedContent" data-toggle="collapse" type="button">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <div class="mx-auto">
        <ul class="navbar-nav">
          <li  class="nav-item" >
            <a class="nav-link" href="/">Home<span class="sr-only">(current)</span>
            </a>
          </li>
          <li  class="nav-item" >
            <a class="nav-link" href="/past">Past WACs</a>
          </li>
          <li  class="nav-item" >
            <a class="nav-link" href="/proceedings">Proceedings</a>
          </li>
          <li  class="nav-item" >
            <a class="nav-link" href="/code-of-conduct">Code of Conduct</a>
          </li>
        </ul>
      </div>
    </div>
  </nav>

  <main class="container">
    
<div class=" mb-5 mx-auto">
  <div class="row justify-content-md-center">
    <div class="col-sm">
      <h1 class="title text-center" id="title">reNotate: The Crowdsourcing and Gamification of Symbolic Music Encoding</h1>
      <div>
        <div class="author">Ben Taylor, Daniel Shanahan, Matthew Wolf, Jesse T. Allison, David John Baker</div>

        <div class="row">
          <div class="col-xl-6">
            <div class="abstract">Musicologists and music theorists have, for quite some time, hoped to be able to make use of computational methods to examine large corpora of music. As far back as the 1940s, an IBM card-sorter was used to implement patternfinding in traditional British folk songs (Bronson 1949, 1959). Alan Lomax famously implemented statistical methods in his Cantometrics project (Lomax, 1968), which sought to collate a large corpus of folk music from across many cultures. In the 1980s and 90s, a number of encoding projects were instituted in an attempt to be able to make searchable music notation on a large scale. The Essen Folksong Collection (Schaffrath, 1995) collected ethnographic transcriptions, whereas projects at the Center for Computer Assisted Research in the Humanities (CCARH) focused on scores in the Western Art Music tradition (Bach chorales, Mozart sonatas, instrumental themes, etc.). Recently, scholars have focused on improving Optical Music Recognition, in the hopes of facilitating the acquisition of large numbers of musical scores (Fujinaga, et al., 2014), but non-notated music, such as improvisational jazz, is often overlooked. While there have been many advances in music information retrieval in recent years, parameters that would facilitate in-depth musicological analysis are still out of reach (for example, stream segregation to examine specific melodic lines, or the analysis of harmony at a resolution that would allow for an analysis of specific chord voicings). Our project seeks to implement methods similar to those used in CAPTCHA and RECAPTCHA technology to crowdsource the symbolic encoding of musical information through a web-based gaming interface. The introductory levels ask participants to tap along with an audio recording's tempo, giving us an approximate BPM, while the second level asks for participants to tap with onsets. The third level asks them to match a contour of a three-note segment, and the final stage asks for specific note matching within that contour. A social-gaming interface allows for users to compete against one another. It is our hope that this work can be generalized to many types of musical genres, and that a web-based framework might facilitate the encoding of musicological and music-theoretic datasets that might be underrepresented by current MIR work.</div>
          </div>
          <div class="col-xl-6">
            <pre class="bibtex">
            <code>
@inproceedings&#123;2016_EA_34,
  abstract = &#123;Musicologists and music theorists have, for quite some time, hoped to be able to make use of computational methods to examine large corpora of music. As far back as the 1940s, an IBM card-sorter was used to implement patternfinding in traditional British folk songs (Bronson 1949, 1959). Alan Lomax famously implemented statistical methods in his Cantometrics project (Lomax, 1968), which sought to collate a large corpus of folk music from across many cultures. In the 1980s and 90s, a number of encoding projects were instituted in an attempt to be able to make searchable music notation on a large scale. The Essen Folksong Collection (Schaffrath, 1995) collected ethnographic transcriptions, whereas projects at the Center for Computer Assisted Research in the Humanities (CCARH) focused on scores in the Western Art Music tradition (Bach chorales, Mozart sonatas, instrumental themes, etc.). Recently, scholars have focused on improving Optical Music Recognition, in the hopes of facilitating the acquisition of large numbers of musical scores (Fujinaga, et al., 2014), but non-notated music, such as improvisational jazz, is often overlooked. While there have been many advances in music information retrieval in recent years, parameters that would facilitate in-depth musicological analysis are still out of reach (for example, stream segregation to examine specific melodic lines, or the analysis of harmony at a resolution that would allow for an analysis of specific chord voicings). Our project seeks to implement methods similar to those used in CAPTCHA and RECAPTCHA technology to crowdsource the symbolic encoding of musical information through a web-based gaming interface. The introductory levels ask participants to tap along with an audio recording's tempo, giving us an approximate BPM, while the second level asks for participants to tap with onsets. The third level asks them to match a contour of a three-note segment, and the final stage asks for specific note matching within that contour. A social-gaming interface allows for users to compete against one another. It is our hope that this work can be generalized to many types of musical genres, and that a web-based framework might facilitate the encoding of musicological and music-theoretic datasets that might be underrepresented by current MIR work.&#125;,
  address = &#123;Atlanta, GA, USA&#125;,
  author = &#123;Taylor, Ben and Shanahan, Daniel and Wolf, Matthew and Allison, Jesse T. and Baker, David John&#125;,
  booktitle = &#123;Proceedings of the International Web Audio Conference&#125;,
  editor = &#123;Freeman, Jason and Lerch, Alexander and Paradis, Matthew&#125;,
  month = &#123;April&#125;,
  pages = &#123;&#125;,
  publisher = &#123;Georgia Tech&#125;,
  series = &#123;WAC '16&#125;,
  title = &#123;reNotate: The Crowdsourcing and Gamification of Symbolic Music Encoding&#125;,
  year = &#123;2016&#125;,
  ISSN = &#123;2663-5844&#125;
}
              </code>
            </pre>
          </div>
        </div>
        <div class="row mb-5">
          <div class="col-xl-6">
            <div>
              
              <a href="/_data/papers/pdf/2016/2016_34.pdf" target="blank" class="PDF">Download PDF</a>
               
              <a href="https://smartech.gatech.edu/bitstream/handle/1853/54658/renotate_video.html?sequence=5&isAllowed=y" target="blank" class="media">Watch video</a>
              
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</div>
  </main>

  <footer class="fixed-bottom py-2 bg-dark text-light">
    <div class="container-fluid">
      <div class="row" style="color:gray;">
        <div class="col-md-6 text-md-left text-center align-self-center" id="developers">
          Developed by: <a href="https://github.com/MeltingPlanet" target="_blank" class="devLink" rel="noopener">JÃ¸rgen Varpe</a> and
          <a href="https://github.com/MeltingPlanet" target="_blank" class="devLink" rel="noopener">Eigil Aandahl</a>
        </div>
        <div class="col-md-6 text-md-right text-center align-self-center">
          <a href="https://twitter.com/webaudioconf" target="_blank" rel="noopener">
            <img src="/assets/images/twitter.svg" width="40px" height="40px" id="bird" />
          </a>
        </div>
      </div>
    </div>
  </footer>

  <script crossorigin="anonymous" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo"
    src="https://code.jquery.com/jquery-3.3.1.slim.min.js"></script>
  <script crossorigin="anonymous" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1"
    src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js"></script>
  <script crossorigin="anonymous" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM"
    src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js"></script>
</body>

</html>
